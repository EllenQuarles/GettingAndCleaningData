---
title: "README"
author: '*Ellen Quarles*'
date: "April 19, 2020"
output:
  html_document:
    theme: readable
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Overview of Getting and Cleaning Data Final Assignment

This assignment, from week 4 of the Coursera course: Getting and Cleaning Data uses data from...  

###### Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz.
###### Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine.  
###### International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012  

...to explore the process of cleaning data, tidying it, summarizing it, and creating clear and effective README and code books. The R script "run_analysis.R" reads in the downloaded data, combines test and training data back into one dataset, and applies/reorganizes row and column labels so the data are more readable. It then averages the data related to mean() and std() by both activty and subject, and that resulting tidy dataset is saved as a txt file "tidydataset.txt".

### Original Dataset Overview

##### From the original README for this dataset:

>Human Activity Recognition Using Smartphones Dataset Version 1.0  

>Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto.  
Smartlab - Non Linear Complex Systems Laboratory  
DITEN - UniversitÃ  degli Studi di Genova.  
Via Opera Pia 11A, I-16145, Genoa, Italy.  
activityrecognition@smartlab.ws  
www.smartlab.ws  

>"The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data."  
"The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details."   

A link to the dataset description:  
http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones  

A link to the zipfile:  
https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip  

The dataset provided by the course came in a zip file named "UCI HAR Dataset". This contains:  

- **README.txt**: The original readme that came with the dataset  
- **activity_labels.txt**: a table of activity codes and labels (i.e. walking (1), standing (2) etc)  
- **features.txt**: table of column names for X_test.txt and X_train.txt (i.e. "tBodyAcc-mean()-X")
- **features_info.txt**: descriptions of features (measurments) taken and the calculations made  

- **./test/subject_test.txt**: table of subject codes (1~30), used as row labels for X_test  
- **./test/X_test.txt**: table of measurements between [-1,1], columns=features, rows=subjects & activities  
- **./test/y_test.txt**: row labels of activity codes for X_test  

- **./train/subject_train.txt**: *same as subject_test, but for X_train*  
- **./train/X_train.txt**: table of measurements between [-1,1], columns=features, rows=subjects & activities  
- **./train/y_train.txt**: row labels of activity codes for X_train  
   
   
### "run-analysis.R" script description

This script is designed to use the UCI HAR Dataset and:  

A) Merge the training and the test sets to create one data set.  
B) Apply the feature names as the column names.  
C) Extract only the measurements on the mean and standard deviation for each measurement.  
D) Use descriptive activity names to name the activities in the data set.  
E) Appropriately label the data set with descriptive variable names.  
F) From the data set in step 4, create a second, independent tidy data set with the average of each variable for each activity and each subject.  


### "tidydataset.txt" description

The tidy data is arranged as a table with the following variable (column) names/descriptions:

**SubjectCode** - integer 1:30 - code number unique to each of the 30 human subjects  

*all following variables are characters*  
**Activity** - standing/laying/walking etc - 6 different activities each subject performed  
**SignalDomain** - "time" or "frequency" - denoting the type of data in the original dataset, either a measurement taken over time or a Fourier transformation of that data into a frequency  
**AccelerationComponent** - "body" or "gravity" - type of measurement  
**Sensor** - notation about which sensor was used to collect data: the gyrometer or accelerometer  
**DerivedValue** - if available, which derivation of the data this represents - the jerk, magnitude, magnitude of jerk, or "" for non-derived value  
**Axis** - X or Y or Z or "" to represent all combined 

*both meanOf... variables are numeric*  
**meanOfMean** - the mean of all of the mean() values for this group  
**meanOfStandardDeviation** - the mean of all of the sd() values for this group  

Each row is an observation of a subject at a unique combination of all other qualitative variables.


